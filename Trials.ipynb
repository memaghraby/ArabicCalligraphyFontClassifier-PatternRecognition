{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import imutils\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import sobel\n",
    "from skimage.exposure import histogram\n",
    "from skimage import feature\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing, binary_opening\n",
    "from __future__ import division\n",
    "from scipy.signal import convolve2d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA =\"./ACdata_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trials Block\n",
    "def closingMinusImageRatio(image):\n",
    "    image = np.asarray(image)\n",
    "    closing = binary_closing(image)\n",
    "    diff = closing - image\n",
    "    whiteOriginal = np.sum(image[image == 1])\n",
    "    whiteDiff = np.sum(diff[diff == 1])\n",
    "    return whiteDiff / whiteOriginal\n",
    "\n",
    "\n",
    "def getBaseline(image):\n",
    "    img_row_sum = np.argmax(np.sum(image, axis=1))\n",
    "    return img_row_sum\n",
    "\n",
    "\n",
    "def largestComponentRatio(image):\n",
    "    image = image.astype('uint8')\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    sizes = stats[:, -1]\n",
    "    countOfConnectedComp = len(output)\n",
    "    # print(countOfConnectedComp)\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    for i in range(2, nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "\n",
    "    img2 = np.zeros(output.shape)\n",
    "    img2[output == max_label] = 255\n",
    "    #show_images([image, img2])\n",
    "    whiteAll = np.sum(image[image == 1])\n",
    "    whiteComponent = np.sum(img2[img2 == 255])\n",
    "\n",
    "    img2 = img2.astype('uint8')\n",
    "    contours = cv2.findContours(img2, 1, 2)\n",
    "    contours = sorted(contours[0], key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "    angle = cv2.minAreaRect(contours[0])[2]\n",
    "    #print(\"angle: \", angle)\n",
    "\n",
    "    return whiteComponent / (whiteAll * image.shape[0] * image.shape[1]), countOfConnectedComp, angle\n",
    "\n",
    "def averageAngle(image):\n",
    "    image = image.astype(np.uint8)\n",
    "    contours = cv2.findContours(image, 1, 2)\n",
    "    contours = sorted(contours[0], key=lambda x: cv2.contourArea(x), reverse=True)[:4]\n",
    "    image2 = np.copy(image)\n",
    "    angle = 0\n",
    "    i = 0\n",
    "    for cnt in contours:\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        angle += rect[2]\n",
    "        i +=1\n",
    "        box = np.int0(box)\n",
    "        #cv2.drawContours(image2, [box], 0, 1, 2)\n",
    "    angle = angle/i\n",
    "    #print(\"average angle: \", angle)\n",
    "    #show_images([image, image2])\n",
    "    return angle    \n",
    "\n",
    "\n",
    "def getRatio(image, baseline, level):\n",
    "    if level == -1:\n",
    "        image_low = image[baseline:,:]\n",
    "        white = np.sum(image_low[image_low == 1])\n",
    "        black = image_low.shape[0] * image_low.shape[1] - white\n",
    "    elif level == 1:\n",
    "        image_high = image[:baseline,:]\n",
    "        white = np.sum(image_high[image_high == 1])\n",
    "        black = image_high.shape[0] * image_high.shape[1] - white\n",
    "    else:\n",
    "        white = np.sum(image[image == 1])\n",
    "        black = image.shape[0] * image.shape[1] - white\n",
    "    #print(white, black, image.shape[0] * image.shape[1])\n",
    "    if black == 0:\n",
    "        black = 0.00001\n",
    "    ratio = white / black\n",
    "    return ratio\n",
    "\n",
    "def horizontalProjection(image):\n",
    "    hProj = np.max(np.sum(image, axis = 1))\n",
    "    return hProj\n",
    "def verticalProjection(image):\n",
    "    vProj = np.max(np.sum(image, axis = 0))\n",
    "    return vProj\n",
    "def HVLines(image):\n",
    "    gray = rgb2gray(image)\n",
    "    edges = cv2.Canny(image,200,100)\n",
    "    linesVert = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=250)\n",
    "    linesHoriz = cv2.HoughLinesP(edges, 1, np.pi, 50, maxLineGap=250)\n",
    "    if linesHoriz is None:\n",
    "        linesHoriz=[]\n",
    "    if linesVert is None:\n",
    "        linesVert=[] \n",
    "    return len(linesVert),len(linesHoriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpq(img):\n",
    "    rho=0.90\n",
    "    winSize=3\n",
    "    STFTalpha=1/winSize  \n",
    "    img=np.float64(img) # Convert np.image to double\n",
    "    radius=(winSize-1)/2 \n",
    "    x=np.arange(-radius,radius+1)[np.newaxis] # Form spatial coordinates in window\n",
    "    w0=np.ones_like(x)\n",
    "    w1=np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "    w2=np.conj(w1)\n",
    "\n",
    "    ## Run filters to compute the frequency response in the four points\n",
    "    filterResp1=convolve2d(convolve2d(img,w0.T,'valid'),w1,'valid')\n",
    "    filterResp2=convolve2d(convolve2d(img,w1.T,'valid'),w0,'valid')\n",
    "    filterResp3=convolve2d(convolve2d(img,w1.T,'valid'),w1,'valid')\n",
    "    filterResp4=convolve2d(convolve2d(img,w1.T,'valid'),w2,'valid')\n",
    "\n",
    "    # Initilize frequency domain matrix for four frequency coordinates\n",
    "    freqResp=np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                        filterResp2.real, filterResp2.imag,\n",
    "                        filterResp3.real, filterResp3.imag,\n",
    "                        filterResp4.real, filterResp4.imag])\n",
    "\n",
    "    #Perform quantization and compute LPQ codewords\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis,np.newaxis,:]\n",
    "    LPQdesc=((freqResp>0)*(2**inds)).sum(2)\n",
    "\n",
    "    LPQdesc=np.histogram(LPQdesc.flatten(),range(100))[0]\n",
    "    LPQdesc=LPQdesc/LPQdesc.sum()\n",
    "    return LPQdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() \n",
    "\n",
    "def get_accuracy(pred, Y):\n",
    "    return round(sum(pred == Y) * 100 / float(len(Y)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getBoundingBox(image):\n",
    "    coords = cv2.findNonZero(image) # Find all non-zero points (text)\n",
    "    x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n",
    "    rect = image[y:y+h, x:x+w]\n",
    "    return rect\n",
    "\n",
    "\n",
    "def unifyBackground(image):\n",
    "    line1 = image[0,:]\n",
    "    line2 = image[-1,:]\n",
    "    avg1 = np.average(line1)\n",
    "    avg2 = np.average(line2)\n",
    "    avg = (avg1 + avg2) / 2\n",
    "    if avg > 0.5:\n",
    "        image = 1-image\n",
    "    return image\n",
    "\n",
    "\n",
    "def denoise(image):\n",
    "    # Find contours and remove small noise\n",
    "    img=np.copy(image)\n",
    "    img=image.astype(np.uint8)\n",
    "    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    rect_areas = []\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        rect_areas.append(w * h)\n",
    "    avg_area = np.mean(rect_areas)\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cnt_area = w * h\n",
    "        if cnt_area < 0.01 * avg_area:\n",
    "            img[y:y + h, x:x + w] = 0          \n",
    "    return img        \n",
    "\n",
    "\n",
    "def preprocessing(image):\n",
    "    gray = rgb2gray(image)\n",
    "    # gray=cv2.resize(gray,(400,200))\n",
    "    thresh = threshold_otsu(gray)\n",
    "    gray[gray > thresh] = 1\n",
    "    gray[gray < thresh] = 0\n",
    "    gray = unifyBackground(gray)\n",
    "    denoised= denoise(gray)\n",
    "    gray = getBoundingBox(denoised)\n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "trainImage = []\n",
    "labels = []\n",
    "features = []\n",
    "test_cases = os.listdir(PATH_TO_DATA)\n",
    "test_cases.sort()\n",
    "for font in test_cases:\n",
    "        for image in pathlib.Path(PATH_TO_DATA + '/' + font).iterdir():\n",
    "            trainImage.append(image)\n",
    "            labels.append(float(font))\n",
    "\n",
    "for image in trainImage:\n",
    "    img = cv2.imread(str(image))\n",
    "    preprocessedImg = preprocessing(img)\n",
    "    lp=lpq(preprocessedImg)\n",
    "    features.append(lp)\n",
    "\n",
    "features = np.asarray(features)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.2,random_state=101) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=25, random_state=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = features\n",
    "Y_train = labels\n",
    "\n",
    "# clf = MLPClassifier(random_state=1, max_iter=200 , hidden_layer_sizes=(255, 1000))\n",
    "# clf2 = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
    "# clf3 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf4= RandomForestClassifier(max_depth=25, random_state=1)\n",
    "# clf5= svm.SVC(gamma=20,C=200)\n",
    "\n",
    "        \n",
    "#Train the model using the training sets\n",
    "# clf.fit(X_train, Y_train)\n",
    "# clf2.fit(X_train, Y_train)\n",
    "# clf3.fit(X_train, Y_train)\n",
    "clf4.fit(X_train,Y_train)\n",
    "# clf5.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Completed_model.joblib']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export random forest module\n",
    "filename = \"Completed_model.joblib\"\n",
    "joblib.dump(clf4, filename)\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "# pred=clf.predict_proba(X_test)\n",
    "# correct=0\n",
    "# j=0\n",
    "# for i in pred:\n",
    "#     a=np.argmax(i)\n",
    "#     a=float(a)+1\n",
    "#     if (a)==Y_test[j]:\n",
    "#         correct=correct+1\n",
    "#     j=j+1\n",
    "\n",
    "# pred_test2 = clf2.predict(X_test)\n",
    "# pred_test3 = clf3.predict(X_test)\n",
    "# pred_test4 = clf4.predict(X_test)\n",
    "# pred_test5 = clf5.predict(X_test)\n",
    "\n",
    "\n",
    "# print(\"MLP:\", correct*100/len(Y_test))\n",
    "# print(\"Decision Tree: \", (pred_test2))\n",
    "# print(\"KNN: \", (pred_test3))\n",
    "# print(\"Random Forrest: \" ,(pred_test4))\n",
    "# print(\"SVM: \" ,(pred_test5))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b56a2cac7f96870531a93a0cdb34fd78b69d45aa71c3ee8be13a6d895e9ad837"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
